{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primetals Python implementation of cifar100 Geometrically Inspired Kernel Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from func import divide_data_into_non_iid_label_screw, Classifier, predictionClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the random seed\n",
    "np.random.seed(4232)\n",
    "\n",
    "# Define the root folder\n",
    "dataset_folder = os.path.join(os.getcwd(),'Datasets', 'CIFAR-100')\n",
    "\n",
    "# Load training and testing images (assuming folders 'train' and 'test')\n",
    "training_dataset = image_dataset_from_directory(os.path.join(dataset_folder, 'TRAIN'),\n",
    "                                                label_mode='int', image_size=(224, 224), shuffle=False)\n",
    "testing_dataset = image_dataset_from_directory(os.path.join(dataset_folder, 'TEST'),\n",
    "                                                label_mode='int', image_size=(224, 224), shuffle=False)\n",
    "\n",
    "# Initialize the feature matrix for training data\n",
    "num_training_files = len(training_dataset.file_paths)\n",
    "y_data_trn = np.zeros((2048, num_training_files))\n",
    "# Load features for training data\n",
    "for i, file_path in enumerate(training_dataset.file_paths):\n",
    "    base_name, _ = os.path.splitext(os.path.basename(file_path))\n",
    "    mat_file = os.path.join(os.path.dirname(file_path), f'{base_name}_resnet50.mat')\n",
    "    #print(f'Reading feature of file = {file_path}')\n",
    "    resnet50_features = scipy.io.loadmat(mat_file)['resnet50_features']\n",
    "    y_data_trn[:, i] = resnet50_features.flatten()\n",
    "\n",
    "# Apply tanh activation\n",
    "y_data_trn = np.tanh(y_data_trn)\n",
    "\n",
    "# Get training labels\n",
    "training_labels = np.concatenate([labels for _, labels in training_dataset], axis=0)\n",
    "classes = np.unique(training_labels)\n",
    "C = len(classes)\n",
    "\n",
    "# Initialize the feature matrix for testing data\n",
    "num_testing_files = len(testing_dataset.file_paths)\n",
    "y_data_test = np.zeros((2048, num_testing_files))\n",
    "labels_trn = training_labels\n",
    "# Load features for testing data\n",
    "for i, file_path in enumerate(testing_dataset.file_paths):\n",
    "    base_name, _ = os.path.splitext(os.path.basename(file_path))\n",
    "    mat_file = os.path.join(os.path.dirname(file_path), f'{base_name}_resnet50.mat')\n",
    "    #print(f'Reading feature of file = {file_path}')\n",
    "    resnet50_features = scipy.io.loadmat(mat_file)['resnet50_features']\n",
    "    y_data_test[:, i] = resnet50_features.flatten()\n",
    "\n",
    "# Apply tanh activation\n",
    "y_data_test = np.tanh(y_data_test)\n",
    "\n",
    "# Get testing labels\n",
    "testing_labels = np.concatenate([labels for _, labels in testing_dataset], axis=0)\n",
    "\n",
    "# Map testing labels to indices\n",
    "labels_test = testing_labels\n",
    "\n",
    "n_clients = 100\n",
    "n_experiments = 3\n",
    "avg_local_acc_arr = np.zeros(n_experiments)\n",
    "avg_global_acc_arr = np.zeros(n_experiments)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(n_experiments):\n",
    "    client_id_trn = divide_data_into_non_iid_label_screw(labels_trn, n_clients, round(0.2 * C))\n",
    "    local_acc_arr = np.zeros(n_clients)\n",
    "    distance_matrix = np.full((C, y_data_test.shape[1]), np.inf)\n",
    "\n",
    "    for j in range(n_clients):\n",
    "        clf = Classifier(y_data_trn[:, client_id_trn == j+1], labels_trn[client_id_trn == j+1], 20, 1000)\n",
    "        classes_client = np.unique(labels_trn[client_id_trn == j+1])\n",
    "\n",
    "        # Select the test data belonging to the classes present in this client\n",
    "        test_data_ind = np.hstack([np.where(labels_test == cls)[0] for cls in classes_client])\n",
    "        y_data_test_client = y_data_test[:, test_data_ind]\n",
    "        labels_test_client = labels_test[test_data_ind]\n",
    "\n",
    "        distance_arr, labels_predicted = predictionClassifier(y_data_test_client, clf)\n",
    "        local_acc_arr[j] = np.mean(labels_predicted == labels_test_client)\n",
    "\n",
    "        for i, test_ind in enumerate(test_data_ind):\n",
    "            distance_matrix[labels_predicted[i], test_ind] = min(distance_arr[i], distance_matrix[labels_predicted[i], test_ind])\n",
    "\n",
    "    # Determine global predictions\n",
    "    min_distance = np.min(distance_matrix, axis=0)\n",
    "    hat_labels_test = np.zeros(y_data_test.shape[1], dtype=int)\n",
    "    for i in range(C):\n",
    "        hat_labels_test[distance_matrix[i, :] == min_distance] = i# + 1\n",
    "\n",
    "    # Global accuracy calculation\n",
    "    global_acc_arr = np.zeros(n_clients)\n",
    "    for j in range(n_clients):\n",
    "        classes_client = np.unique(labels_trn[client_id_trn == j+1])\n",
    "        test_data_ind = np.hstack([np.where(labels_test == cls)[0] for cls in classes_client])\n",
    "        global_acc_arr[j] = np.mean(hat_labels_test[test_data_ind] == labels_test[test_data_ind])\n",
    "\n",
    "    avg_local_acc_arr[k] = np.mean(local_acc_arr)\n",
    "    avg_global_acc_arr[k] = np.mean(global_acc_arr)\n",
    "\n",
    "# Compute final results\n",
    "mean_local_acc_20 = np.mean(avg_local_acc_arr)\n",
    "std_local_acc_20 = np.std(avg_local_acc_arr)\n",
    "mean_global_acc_20 = np.mean(avg_global_acc_arr)\n",
    "std_global_acc_20 = np.std(avg_global_acc_arr)\n",
    "\n",
    "print(f\"Local accuracy (20%): {mean_local_acc_20:.6f}, std = {std_local_acc_20:.6f}\")\n",
    "print(f\"Global accuracy (20%): {mean_global_acc_20:.6f}, std = {std_global_acc_20:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
