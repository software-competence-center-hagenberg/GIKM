{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primetals Python implementation of fashion mnist Geometrically Inspired Kernel Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import os\n",
    "import scipy\n",
    "from keras import datasets\n",
    "from func import Classifier, predictionClassifier, combineMultipleClassifiers, divide_data_into_non_iid_label_screw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "x_train_flattened = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "\n",
    "# Step 2: Transpose to get shape (784, 100000)\n",
    "y_data_trn = x_train_flattened.T /255\n",
    "#y_data_trn = np.zeros((x_train.shape[0] * x_train.shape[1], x_train.shape[0]))\n",
    "\n",
    "# Flatten and normalize the training images\n",
    "\n",
    "# Apply the tanh activation function\n",
    "y_data_trn = np.tanh(y_data_trn)\n",
    "\n",
    "# Process the training labels\n",
    "labels = np.unique(y_train)\n",
    "labels_trn = y_train.T\n",
    "\n",
    "\n",
    "\n",
    "# Initialize y_data_test\n",
    "x_test_flattened = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\n",
    "\n",
    "# Step 2: Transpose to get shape (784, 100000)\n",
    "y_data_test = x_test_flattened.T /255\n",
    "\n",
    "# Apply the tanh activation function\n",
    "y_data_test = np.tanh(y_data_test)\n",
    "\n",
    "# Process the test labels\n",
    "labels_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 100\n",
    "n_experiments = 3\n",
    "avg_local_acc_arr = np.zeros(n_experiments)\n",
    "avg_global_acc_arr = np.zeros(n_experiments)\n",
    "for k in range(n_experiments):\n",
    "    n_samples_per_client = round(0.3 * len(labels))\n",
    "    client_id_trn = divide_data_into_non_iid_label_screw(labels_trn, n_clients, n_samples_per_client)\n",
    "    local_acc_arr = np.zeros(n_clients)\n",
    "    distance_matrix = np.full((len(labels), y_data_test.shape[1]), np.inf)\n",
    "    for j in range(n_clients):\n",
    "        test = client_id_trn == (j+1)\n",
    "        sub_data = y_data_trn[:,test]\n",
    "        sub_labels = labels_trn[client_id_trn == (j+1)]\n",
    "        CLF = Classifier(sub_data,sub_labels , 20, 1000)\n",
    "        classes_client = np.unique(labels_trn[client_id_trn == (j+1)])\n",
    "        test_data_ind = []\n",
    "        for i in range(len(classes_client)):\n",
    "            test_data_ind.extend(np.where(labels_test == classes_client[i])[0])\n",
    "        \n",
    "        y_data_test_client = y_data_test[:, test_data_ind]\n",
    "        labels_test_client = labels_test[test_data_ind]\n",
    "        distance_arr, labels_predicted = predictionClassifier(y_data_test_client, CLF)\n",
    "        local_acc_arr[j] = np.mean(labels_predicted == labels_test_client)\n",
    "        \n",
    "        for i in range(len(test_data_ind)):\n",
    "            distance_matrix[labels_predicted[i], test_data_ind[i]] = min(distance_arr[i], distance_matrix[labels_predicted[i], test_data_ind[i]])\n",
    "    \n",
    "    min_distance = np.min(distance_matrix, axis=0)\n",
    "    hat_labels_test = np.zeros(y_data_test.shape[1], dtype=int)\n",
    "    for i in range(len(labels)):\n",
    "        hat_labels_test[distance_matrix[i, :] == min_distance] = i# + 1\n",
    "    \n",
    "    global_acc_arr = np.zeros(n_clients)\n",
    "    for j in range(n_clients):\n",
    "        classes_client = np.unique(labels_trn[client_id_trn == (j+1)])\n",
    "        test_data_ind = []\n",
    "        for i in range(len(classes_client)):\n",
    "            test_data_ind.extend(np.where(labels_test == classes_client[i])[0])\n",
    "        \n",
    "        global_acc_arr[j] = np.mean(hat_labels_test[test_data_ind] == labels_test[test_data_ind])\n",
    "    \n",
    "    avg_local_acc_arr[k] = np.mean(local_acc_arr)\n",
    "    avg_global_acc_arr[k] = np.mean(global_acc_arr)\n",
    "\n",
    "mean_local_acc_30 = np.mean(avg_local_acc_arr)\n",
    "std_local_acc_30 = np.std(avg_local_acc_arr)\n",
    "mean_global_acc_30 = np.mean(avg_global_acc_arr)\n",
    "std_global_acc_30 = np.std(avg_global_acc_arr)\n",
    "\n",
    "print(f'Mean Local Accuracy (30%): {mean_local_acc_30:.4f}')\n",
    "print(f'STD Local Accuracy (30%): {std_local_acc_30:.4f}')\n",
    "print(f'Mean Global Accuracy (30%): {mean_global_acc_30:.4f}')\n",
    "print(f'STD Global Accuracy (30%): {std_global_acc_30:.4f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
